{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***RAG Implementation Workflow***\n",
    "1. Load Documents\n",
    "2. Generate Document Chunks\n",
    "3. Vectorize Document Chunks\n",
    "4. Store Embeddings with Document Chunk IDs\n",
    "5. Vectorize Question/Query\n",
    "6. Use Question Embeddings to Retrieve Relevant Document Chunk IDs\n",
    "7. Use Document Chunk IDs to Retrieve Document Chunks from Storage\n",
    "8. Use Question + Relevant Document Chunks + Prompt to Answer Questions\n",
    "9. Generate Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Documents**\n",
    "\n",
    "**Task** : Fetch PDF documents from ICAR-CRIDA website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.icar-crida.res.in/./assets_c/img/Annualreports/AR22.pdf', 'https://www.icar-crida.res.in/./assets_c/img/Annualreports/AR21.pdf', 'https://www.icar-crida.res.in/./assets_c/img/Annualreports/AR20.pdf', 'https://www.icar-crida.res.in/./assets/img/Annualreports/AR19.pdf', 'https://www.icar-crida.res.in/./assets_c/img//Annualreports/AR18-19.pdf', 'https://www.icar-crida.res.in/./assets_c/img//Annualreports/AR17-18.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AR16-17.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AR15-16.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AR14-15.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AR13-14.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPDA/AR18-19.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPDA/AR17-18.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPDA/AR16-17.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPDA/AR15-16.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPAM/AR%202016-17.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPAM/2015-16.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPAM/2014-15.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPAM/2013-14.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPAM/2012-13.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/AICRPAM/2011.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/NPCC/FR-2004-07.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/NAIP/NAIP%20Completion%20Report%20Final.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/NATP/PSR%2099-04.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/NICRA/TDC/2015-16.pdf', 'https://www.icar-crida.res.in/assets_c/img/Annualreports/NICRA/TDC/2014-15.pdf']\n",
      "PDF download and URL scraping completed!\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage to scrape\n",
    "url = \"https://www.icar-crida.res.in/publications_annualreports.html\"\n",
    "\n",
    "def fetch_pdf_urls(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        content = BeautifulSoup(response.content, 'html.parser')\n",
    "        links = content.find_all('a')\n",
    "        pdf_links = []\n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            if href and '.pdf' in href:\n",
    "                if not href.startswith('http'):\n",
    "                    href = 'https://www.icar-crida.res.in/' + href.lstrip('/')\n",
    "                pdf_links.append(href)\n",
    "        return pdf_links\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch webpage: {url} with error: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_pdfs(pdf_urls, download_dir='downloaded_pdfs'):\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    for url in pdf_urls:\n",
    "        filename = url.split('/')[-1]\n",
    "        filepath = os.path.join(download_dir, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"Skipping {filename}. Already downloaded.\")\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded {filename} to {download_dir}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to download {filename}: {e}\")\n",
    "\n",
    "# Fetch PDF URLs and download PDFs\n",
    "pdf_urls = fetch_pdf_urls(url)\n",
    "# download_pdfs(pdf_urls)\n",
    "\n",
    "# Save PDF URLs to a JSON file\n",
    "with open('icar_crida_report_urls.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(pdf_urls, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(pdf_urls)\n",
    "print(\"PDF download and URL scraping completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generate Document Chunks***\n",
    "\n",
    "**Task** : Divide the text of each document into smaller chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF processing completed. Results saved to icar_crida_reports_processed_pdfs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Function to chunk data\n",
    "def chunk_data(text, lines_per_chunk=10):\n",
    "    lines = text.split('\\n')\n",
    "    chunks = ['\\n'.join(lines[i:i + lines_per_chunk]) for i in range(0, len(lines), lines_per_chunk)]\n",
    "    return chunks\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\\n\".join(page.get_text() for page in doc)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to process PDFs and generate chunks\n",
    "def process_pdfs(pdf_dir='downloaded_pdfs'):\n",
    "    pdf_texts = []\n",
    "    for filename in tqdm(os.listdir(pdf_dir), desc=\"Processing PDFs\"):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_dir, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            if text:\n",
    "                clean_text_content = clean_text(text)\n",
    "                chunks = chunk_data(clean_text_content)\n",
    "                pdf_texts.append({\n",
    "                    'filename': filename,\n",
    "                    'chunks': chunks,\n",
    "                    'total_chunks': len(chunks)\n",
    "                })\n",
    "    return pdf_texts\n",
    "\n",
    "# Process PDFs and generate chunked text\n",
    "pdf_texts = process_pdfs()\n",
    "\n",
    "# Dump pdf_texts to JSON file\n",
    "output_file = 'icar_crida_reports_processed_pdfs.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(pdf_texts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"PDF processing completed. Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Vectorize Document Chunks***\n",
    "\n",
    "**Task** : Convert each chunk of text into numerical vectors (embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed. Results saved to icar_crida_reports_tokenized.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and saving tokenized chunks\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_text_chunks(pdf_texts):\n",
    "    for pdf in tqdm(pdf_texts, desc=\"Tokenizing Chunks\"):\n",
    "        for chunk in pdf['chunks']:\n",
    "            tokenized_text = tokenizer(chunk, return_tensors='pt', truncation=True, padding=True)\n",
    "            original_text = chunk\n",
    "            tokenized_chunk = {\n",
    "                'original_text': original_text,\n",
    "                'input_ids': tokenized_text['input_ids'].tolist(),\n",
    "                'attention_mask': tokenized_text['attention_mask'].tolist()\n",
    "            }\n",
    "            pdf.setdefault('tokenized_chunks', []).append(tokenized_chunk)\n",
    "    return pdf_texts\n",
    "\n",
    "# Load processed PDF texts\n",
    "with open('icar_crida_reports_processed_pdfs.json', 'r', encoding='utf-8') as f:\n",
    "    pdf_texts = json.load(f)\n",
    "\n",
    "# Tokenize the chunks\n",
    "pdf_texts = tokenize_text_chunks(pdf_texts)\n",
    "\n",
    "# Save tokenized chunks to a JSON file\n",
    "tokenized_output_file = 'icar_crida_reports_tokenized.json'\n",
    "with open(tokenized_output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(pdf_texts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Tokenization completed. Results saved to {tokenized_output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings in all_embeddings: 1, 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT model and tokenizer\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to embed text\n",
    "def embed(text, nums):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    num_tokens = inputs['input_ids'].size(1)  # Get the number of tokens\n",
    "    nums.append(num_tokens)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    mean_embedding = torch.mean(token_embeddings, dim=1)\n",
    "    return mean_embedding.squeeze().tolist()\n",
    "\n",
    "# Function to process and embed PDFs\n",
    "def process_and_embed_pdfs(pdf_texts):\n",
    "    nums = []  # List to store number of tokens processed per chunk\n",
    "    all_embeddings = []  # List to store all embeddings\n",
    "    for pdf in tqdm(pdf_texts, desc=\"Embedding Chunks\"):\n",
    "        pdf.setdefault('tokenized_chunks', [])\n",
    "        for chunk in pdf['chunks']:\n",
    "            original_text = chunk\n",
    "            embeddings = embed(original_text, nums)\n",
    "            tokenized_chunk = {\n",
    "                'original_text': original_text,\n",
    "                'embeddings': embeddings\n",
    "            }\n",
    "            pdf['tokenized_chunks'].append(tokenized_chunk)\n",
    "            all_embeddings.append(embeddings)\n",
    "    return pdf_texts, all_embeddings\n",
    "\n",
    "# Load tokenized PDF texts\n",
    "with open('icar_crida_reports_tokenized.json', 'r', encoding='utf-8') as f:\n",
    "    pdf_texts = json.load(f)\n",
    "\n",
    "# Process and embed the PDFs\n",
    "pdf_texts, all_embeddings = process_and_embed_pdfs(pdf_texts)\n",
    "\n",
    "# Check the shape of embeddings in all_embeddings\n",
    "print(f\"Shape of embeddings in all_embeddings: {len(all_embeddings)}, {len(all_embeddings[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[[-0.3430640697479248, 0.08783604204654694, 0.035757556557655334, -0.1816527098417282, 0.5251249670982361, -0.1327868402004242, 0.02471209689974785, 0.34966331720352173, -0.09805116057395935, -0.12245539575815201, -0.041326649487018585, -0.34544122219085693, -0.0604957677423954, 0.6165102124214172, 0.14404965937137604, 0.7463268041610718, 0.419908732175827, -0.1181224063038826, -0.226030170917511, 0.31585773825645447, 0.2541721761226654, -0.07760126143693924, 0.2717641592025757, 0.7797965407371521, 0.35269099473953247, 0.13884028792381287, 0.29306456446647644, 0.18969954550266266, -0.022022098302841187, -0.06472940742969513, 0.5332173705101013, -0.03516602888703346, -0.18561290204524994, -0.037354208528995514, 0.18858635425567627, -0.10143300890922546, -0.2946678400039673, -0.1413755863904953, -0.14595064520835876, 0.011805424466729164, -0.37029996514320374, -0.5466173887252808, -0.25966358184814453, 0.02492462657392025, -0.14755800366401672, -0.07804714143276215, 0.10139743238687515, 0.2623770236968994, -0.07529482245445251, 0.17360025644302368, -0.13996857404708862, 0.2618989944458008, -0.1179957315325737, -0.40098142623901367, 0.2609824538230896, 0.692118227481842, -0.12551572918891907, -0.2085043489933014, -0.44705092906951904, -0.028508635237812996, 0.31869611144065857, -0.08494867384433746, 0.08121232688426971, -0.3239701986312866, 0.2744259536266327, 0.18986555933952332, 0.1104799211025238, 0.26822298765182495, -0.5569573640823364, -0.0032292157411575317, -0.476632297039032, -0.02990039810538292, -0.26049602031707764, 0.3875119686126709, -0.2507338523864746, -0.2529967725276947, -0.16794078052043915, 0.16626118123531342, -0.03163711726665497, -0.07930243015289307, 0.026577185839414597, 0.09001526981592178, -0.3056047260761261, 0.5360373854637146, 0.1362631916999817, 0.23164445161819458, 0.2755514085292816, 0.1972753405570984, -0.43801820278167725, 0.36744189262390137, 0.08507411926984787, -0.15421295166015625, 0.09066443890333176, 0.2826502323150635, 0.28286921977996826, 0.04311338812112808, 0.1845879703760147, -0.15589848160743713, -0.07868432998657227, 0.23270386457443237, 0.2432795912027359, -0.2555985748767853, 0.15605613589286804, 0.3804782032966614, -0.16678428649902344, -0.10668133944272995, 0.041543323546648026, 0.1829630583524704, -0.3780485987663269, 0.44362831115722656, 0.03332041949033737, -0.11624445766210556, -0.0708688423037529, -0.5597618818283081, -0.12491853535175323, -0.0562773272395134, 0.0774182677268982, 0.0457182340323925, -0.07108765840530396, 0.3054289221763611, 0.30563750863075256, -0.20334768295288086, 0.21475940942764282, 0.9898970127105713, -0.17571522295475006, 0.0577334463596344, -0.1219068318605423, 0.18113969266414642, 0.09414071589708328, 0.06835765391588211, 0.09397631138563156, 0.14873960614204407, -0.1896628886461258, -0.271833598613739, -0.42842942476272583, 0.11730663478374481, 0.08739091455936432, -0.3309231400489807, -0.21427658200263977, 0.07102678716182709, -0.1478790044784546, -0.4214908480644226, 0.5991600155830383, -0.011656146496534348, 0.004111886024475098, 0.042705923318862915, -0.06680011749267578, 0.031156916171312332, -0.07162284106016159, 0.1400681734085083, 0.19701524078845978, 0.04071228578686714, -0.30902835726737976, -0.04470016062259674, -0.2115224003791809, -0.013048027642071247, -0.4624030292034149, 0.37274444103240967, 0.08304854482412338, 0.08164913952350616, 0.19293314218521118, -0.05020740628242493, -0.35732409358024597, 0.3133111894130707, -0.25009721517562866, -0.07176412642002106, 0.13543033599853516, 0.23819467425346375, -0.3294355869293213, -0.09775983542203903, -0.07954548299312592, -0.33445364236831665, 0.4410151243209839, -0.17583568394184113, 0.09862828254699707, -0.03043166548013687, 0.32048964500427246, 0.003293633460998535, -0.05085928365588188, 0.20488351583480835, -0.8591756820678711, 0.17587792873382568, 0.05390850454568863, 0.16498100757598877, 0.12294784188270569, -0.16658805310726166, 0.3093010187149048, -0.3034409284591675, 0.1835966855287552, -0.16479316353797913, -0.035200200974941254, -0.3742939233779907, -0.0703415498137474, 0.006083444692194462, 0.35301727056503296, -0.19872607290744781, 0.09667257219552994, -0.10039563477039337, -0.2900351285934448, -0.025022584944963455, -0.037420038133859634, 0.2719821333885193, 0.32024669647216797, 0.21953921020030975, -0.22951245307922363, -0.41723647713661194, 0.05410632863640785, -0.26731887459754944, -0.05749339982867241, 0.28242963552474976, -0.3218178153038025, 0.080809585750103, 0.25270140171051025, -0.028565870597958565, -0.11359995603561401, -0.010834717191755772, -0.2781837284564972, 0.17740865051746368, 0.1558237224817276, 0.016699858009815216, 0.23205289244651794, 0.05674463137984276, -0.4169273376464844, 0.6460503935813904, -0.11526364088058472, 0.6798247694969177, 0.21507881581783295, -0.8059040307998657, 0.43024498224258423, 0.45582714676856995, 0.18094216287136078, -0.5072630643844604, 0.6690951585769653, -0.12569081783294678, -0.3143737316131592, 0.15347391366958618, -0.37732410430908203, 0.024488277733325958, 0.11923433840274811, -0.41584765911102295, -0.3468610942363739, 0.6184870004653931, 0.3362179398536682, 0.10391714423894882, 0.009622294455766678, -0.07717464864253998, -0.028832197189331055, -0.04926956817507744, -0.2241126000881195, -0.2860352396965027, -0.29304447770118713, 0.023657578974962234, 0.03806852549314499, -0.4590422511100769, -0.25612759590148926, -0.15282943844795227, -0.19061456620693207, -0.5571776628494263, 0.0033873850479722023, 0.11253713071346283, 0.3037831485271454, -0.14241531491279602, 0.1850338876247406, -0.1742800623178482, -0.23269057273864746, -0.45731836557388306, 0.2633019685745239, 0.13042299449443817, 0.16758102178573608, 0.018627673387527466, 0.11738771200180054, 0.08984418213367462, 0.030521363019943237, 0.7367955446243286, -0.27373582124710083, -0.45024335384368896, 0.32408320903778076, 0.23093166947364807, -0.1995299756526947, 0.015618978068232536, 0.3357894718647003, 0.26578640937805176, -0.2017340064048767, -0.061654478311538696, -0.25745755434036255, 0.1118573471903801, 0.1870071291923523, -0.292233943939209, -0.0017906203866004944, -0.32152479887008667, -0.1239890605211258, 0.28127074241638184, -0.22714003920555115, -0.18110299110412598, 0.21819068491458893, -0.053733065724372864, 0.08443004637956619, 0.17077767848968506, 0.3104701638221741, -0.09768997877836227, -0.2567979097366333, -0.19711433351039886, 0.058604948222637177, 0.08297745883464813, -0.19078269600868225, 0.2582852840423584, 0.010242626070976257, -0.6772280931472778, -3.125325918197632, 0.019848018884658813, 0.023877814412117004, -0.3928917944431305, 0.5004569292068481, -0.22999468445777893, 0.1389426589012146, 0.07178126275539398, -0.37946516275405884, 0.17869135737419128, -0.14281108975410461, -0.396215558052063, 0.28113675117492676, 0.07850594073534012, 0.07984829694032669, 0.08722356706857681, 0.11417821049690247, -0.3491020202636719, -0.002527855336666107, 0.2991275191307068, -0.08629775047302246, -0.6096967458724976, 0.07777159661054611, -0.033150311559438705, 0.31138449907302856, 0.3345734477043152, -0.4927385449409485, -0.12201692163944244, -0.4488915205001831, -0.23167812824249268, -0.10843054950237274, -0.4634428024291992, 0.243930846452713, 0.30899691581726074, -0.06387229263782501, -0.0621664896607399, -0.11248374730348587, -0.3698444962501526, -0.2086758017539978, -0.20315510034561157, 0.2100915014743805, -0.7240023612976074, -0.23143988847732544, 0.0007858965545892715, 0.8309617042541504, -0.25258874893188477, 0.07415921241044998, -0.09609989076852798, 0.014705993235111237, 0.16984477639198303, 0.25348860025405884, -0.06749316304922104, -0.18258042633533478, -0.24035470187664032, -0.12706127762794495, -0.15793046355247498, 0.369218647480011, 0.22486211359500885, -0.34505710005760193, -0.29873794317245483, 0.04314111918210983, -0.10652998834848404, -0.5609920620918274, -0.3007589876651764, -0.06542438268661499, -0.01364513672888279, -0.5076955556869507, -0.401212215423584, -0.15784122049808502, -0.3069385290145874, -0.15074415504932404, 0.3619486391544342, -0.2792801856994629, -0.2598448395729065, -0.3018189072608948, -0.48186904191970825, 0.3811987042427063, -0.12604236602783203, -0.2810499668121338, 0.0058700586669147015, -0.3558402955532074, -0.5852857232093811, 0.24341493844985962, -0.04847492277622223, -0.05060790479183197, -0.3509654402732849, 0.2907615005970001, -0.4521551728248596, -0.34428870677948, -0.5745202302932739, 0.4186590313911438, 0.048393119126558304, 0.29954490065574646, 0.15271449089050293, 0.29159000515937805, -0.06990544497966766, 0.23533770442008972, 0.1110888198018074, 0.05443234369158745, -0.5962142944335938, 0.09810979664325714, 0.16120325028896332, 0.4338940382003784, -0.18810053169727325, -0.008740308694541454, 0.009957941249012947, -0.08662936091423035, -0.0343041829764843, 0.1931292712688446, -0.3286181092262268, 0.33719050884246826, -0.584607720375061, 0.4614293575286865, -0.3582448959350586, 0.10629691183567047, 0.020887531340122223, 0.11910898983478546, 0.5887385606765747, -0.03931353986263275, -0.14751780033111572, -0.24090515077114105, 0.33641737699508667, -0.1639755219221115, -0.0038269981741905212, -0.07083407044410706, 0.08921777456998825, -0.2840329110622406, 0.12248045951128006, -0.04695866256952286, -0.2972659468650818, -0.16060736775398254, 0.05426451563835144, -0.05563879758119583, 0.030685707926750183, 0.15167561173439026, 0.40835440158843994, -0.14696991443634033, -0.5516970157623291, -0.2918960154056549, 0.09704529494047165, 0.003505036234855652, 0.3830621838569641, 0.22130867838859558, -0.02973063290119171, 0.2735469341278076, 0.21584030985832214, 0.09292114526033401, 0.19064350426197052, 0.007247008383274078, 0.05788666009902954, -0.5152924060821533, -0.32863089442253113, -0.21963831782341003, -0.2028224617242813, 0.010466870851814747, 0.08792033791542053, 0.4083905816078186, -0.08691031485795975, 0.03678479045629501, -0.17712056636810303, 0.1315799206495285, -0.06460975110530853, 0.15682412683963776, -0.01523713767528534, -0.15944084525108337, 0.7391039133071899, -0.07873605191707611, -0.392625093460083, 0.20653587579727173, 0.24111422896385193, -0.04945840686559677, 0.08903751522302628, -0.050664354115724564, -0.47283947467803955, -0.2273949533700943, 0.24360163509845734, 0.146511971950531, -0.1838141232728958, -0.06277608871459961, 0.41674718260765076, -0.05743306130170822, -0.3192591965198517, -0.24376974999904633, 0.23076489567756653, 0.300811231136322, 0.04885337874293327, 0.21321335434913635, -0.5820728540420532, 0.06651883572340012, 0.24071505665779114, 0.11367398500442505, 0.34682512283325195, 0.19302210211753845, -0.0880747139453888, -0.14624445140361786, -0.4644128680229187, 0.25110888481140137, -0.26913225650787354, -0.2826436758041382, -0.008836828172206879, 0.1825118064880371, -0.07164740562438965, -0.10996361821889877, 0.12620243430137634, -0.1281522810459137, -0.31064724922180176, -0.06375490128993988, 0.31071460247039795, 0.028223861008882523, -0.04905742034316063, -0.5837790966033936, 0.006527891848236322, -0.08343243598937988, -0.011420559138059616, 0.3159598410129547, -0.42272019386291504, -0.20150142908096313, -0.319470077753067, -0.33596158027648926, 0.010729949921369553, -0.02605430781841278, 0.011827896349132061, 0.28066813945770264, -0.17090266942977905, -0.4276084899902344, -0.3106539249420166, 0.29398852586746216, 0.02089320495724678, -0.1698761284351349, -0.02490944415330887, 0.01048286259174347, -1.008385419845581, 0.07782329618930817, 0.15391674637794495, -0.10612094402313232, -0.07068255543708801, -0.007662519812583923, -0.597231388092041, 0.06716106086969376, 0.038550540804862976, -0.2961704134941101, -0.008090982213616371, -0.10899058729410172, -0.3882264494895935, -0.014615999534726143, -0.238886296749115, -0.13517525792121887, 0.5680772066116333, -0.1508447825908661, 0.4040313959121704, -0.11124075949192047, 0.06321324408054352, -0.164254292845726, -0.32637542486190796, 0.2701515555381775, -0.5378431081771851, -0.19061784446239471, 0.007365040481090546, -0.18732275068759918, -0.17393212020397186, -0.17286843061447144, -0.13889451324939728, -0.0034534037113189697, 0.03220192715525627, 0.20879192650318146, -0.37651553750038147, -0.12124768644571304, -0.20109766721725464, 0.3575698733329773, -0.5094356536865234, 0.29422035813331604, -0.28429028391838074, -0.09497307240962982, -0.5208373069763184, 0.24002689123153687, 0.12681686878204346, 0.05612309277057648, -0.30449068546295166, 0.5377086997032166, -0.5720486044883728, -0.08621524274349213, -0.07821889221668243, 0.06683097779750824, 0.1176837757229805, 0.2894112467765808, -0.5064938068389893, -0.041765160858631134, 0.470182865858078, 0.03847656399011612, -0.22959467768669128, 0.38308751583099365, -0.08023439347743988, -0.16716539859771729, 0.1860162317752838, -0.4624314606189728, 0.027450382709503174, 0.5843524932861328, 0.5374006628990173, -0.05641762167215347, 0.043837860226631165, 0.13747920095920563, 0.10019989311695099, 0.36457815766334534, 0.0027714967727661133, -0.17978863418102264, 0.24920979142189026, 0.25299835205078125, -0.4959375858306885, -0.1764308363199234, -0.08266235142946243, 0.09745699912309647, -0.2870725393295288, 0.8562260866165161, 0.2629973888397217, -0.3672856390476227, -0.145830899477005, -0.25855764746665955, -0.006891731172800064, 0.2973465323448181, -0.18720591068267822, 0.24873045086860657, -0.029546624049544334, 0.39453816413879395, 0.016197502613067627, 0.3517496585845947, 0.5849494338035583, -0.4040260314941406, -0.1962200552225113, -0.009293110109865665, 0.4451351761817932, -0.1548786759376526, 0.2710067629814148, -0.2605055868625641, 0.3692784309387207, 0.17451004683971405, 0.20313230156898499, -0.19156992435455322, -0.09082944691181183, 0.0824824869632721, -0.16618755459785461, 0.1479887068271637, 0.14758019149303436, 0.4017687439918518, 0.32642635703086853, 0.3882676362991333, 0.2725050747394562, 0.3637012243270874, 0.1253259778022766, 0.2554693818092346, 0.5636670589447021, 0.060399290174245834, -0.001721397042274475, 0.04594795033335686, 0.014502812176942825, 0.14830796420574188, 0.220412015914917, 0.1217089295387268, 0.07009434700012207, -0.11672644317150116, 0.7774457931518555, 0.1513584852218628, 0.38404208421707153, 0.32165563106536865, -0.36480212211608887, -0.027713976800441742, 0.08375515788793564, 0.4581214189529419, -0.548172116279602, 0.08350712060928345, -0.05078064650297165, 0.2292105257511139, 0.11111976206302643, -0.2917851209640503, -0.10655473172664642, -0.002231532707810402, 0.3371659219264984, -0.02258247882127762, -0.29120194911956787, 0.034117862582206726, 0.03390073403716087, -0.35227370262145996, -0.2584211230278015, -0.34565043449401855, -0.33197474479675293, -0.16623269021511078, -0.2927328944206238, -0.23036357760429382, 0.12029469758272171, -0.15907496213912964, -0.4192255139350891, -0.12352409213781357, 0.0973026305437088, 0.031312696635723114, -0.049420200288295746, -0.2197181135416031, -0.1589210033416748, 0.41632843017578125, 0.2036498636007309, 0.6698850989341736, 0.058808546513319016, 0.24814604222774506, -0.17273226380348206, -0.22234612703323364, 0.013403400778770447, 0.21344518661499023, 0.014411438256502151, 0.06626646220684052, 0.3364427089691162, -0.25710707902908325, 0.03543009236454964, 0.05270581692457199, 0.5792089700698853, -0.42231062054634094, 0.03569159656763077, -0.10583342611789703, 0.1494493931531906, -0.022346198558807373, 0.048134125769138336, -0.47456008195877075, -0.03849297761917114, 0.023220084607601166, -0.4574616551399231, 0.10215676575899124, -0.0723530724644661, -0.4019813537597656, -0.17315910756587982, 0.4003145694732666, 0.39890313148498535, -0.1861409842967987, -0.046203628182411194, 0.09430555999279022, 0.09722678363323212, -0.12563616037368774, 0.3100114166736603, -0.12064188718795776, -0.11907181143760681, -0.3485255241394043, 0.002358105033636093, -0.30080628395080566, 0.008812310174107552, 0.03734315186738968, 0.20815756916999817, 0.09718646854162216, -0.08209513127803802, 0.5455496311187744, -0.1433333456516266, -0.13511933386325836, -0.17308826744556427, 0.033397044986486435, 0.038966331630945206, -0.14426536858081818, 0.1187836155295372, 0.22488358616828918, -0.14868436753749847, 0.06340382993221283, -0.17686156928539276, -0.30425378680229187, -0.2785519063472748, -0.07280035316944122, -0.21962305903434753]]\n"
     ]
    }
   ],
   "source": [
    "print(max(nums))\n",
    "print(all_embeddings[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Store Embeddings with Document Chunk IDs***\n",
    "\n",
    "**Task** : Save the embeddings along with metadata (document chunk IDs, original text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and text chunks saved to pickle files.\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings and text chunks using pickle\n",
    "with open('allembeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(all_embeddings, f)\n",
    "\n",
    "# Save text chunks using pickle\n",
    "text_chunks = [pdf['chunks'] for pdf in pdf_texts]  # Extract chunks from each PDF\n",
    "with open('text_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(text_chunks, f)\n",
    "\n",
    "print(\"Embeddings and text chunks saved to pickle files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Vectorize Question/Query***\n",
    "\n",
    "**Task** : Convert user queries into numerical vectors (embeddings) for similarity matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query_embedding: 768\n",
      "Query vectorization completed!\n"
     ]
    }
   ],
   "source": [
    "# Example query text\n",
    "query_text = \"Who is the current director of ICAR-CRIDA, and who were the members of the editorial committee for the 2022 annual report?\"\n",
    "query_nums = []\n",
    "query_embedding = embed(query_text, query_nums)\n",
    "print(f\"Shape of query_embedding: {len(query_embedding)}\")\n",
    "\n",
    "print(\"Query vectorization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Use Question Embeddings to Retrieve Relevant Document Chunk IDs***\n",
    "\n",
    "**Task** : Retrieve document chunk IDs that are most relevant to the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest IDs: [0]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def find_nearest_embeddings(query_embedding, embeddings, top_k=5):\n",
    "    distances = []\n",
    "    for idx, embedding in enumerate(embeddings):\n",
    "        distance = cosine(query_embedding, embedding)\n",
    "        distances.append((idx, embedding, distance))\n",
    "    distances.sort(key=lambda x: x[2])  # Sort by distance (smaller is closer)\n",
    "    nearest_embeddings = [embedding for _, embedding, _ in distances[:top_k]]\n",
    "    nearest_ids = [idx for idx, _, _ in distances[:top_k]]\n",
    "    return nearest_ids, nearest_embeddings\n",
    "\n",
    "def query(query_embedding, top_k=5):\n",
    "    # Load stored embeddings\n",
    "    with open('allembeddings.pkl', 'rb') as f:\n",
    "        loaded_allembeddings = pickle.load(f)\n",
    "    # Find and return the nearest embeddings\n",
    "    return find_nearest_embeddings(query_embedding, loaded_allembeddings, top_k)\n",
    "\n",
    "# Perform the query\n",
    "nearest_ids, nearest_embeddings = query(query_embedding)\n",
    "print(\"Nearest IDs:\", nearest_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Use Document Chunk IDs to Retrieve Document Chunks from Storage***\n",
    "\n",
    "**Task** : Fetch the actual document chunks corresponding to the retrieved chunk IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Perform the query\n",
    "nearest_ids, nearest_embeddings = query(query_embedding)\n",
    "print(nearest_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Use Question + Relevant Document Chunks + Prompt to Answer Questions***\n",
    "\n",
    "**Task** : Combine the user query, relevant document chunks, and a prompt to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n\u001b[0;32m     54\u001b[0m query_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is the current director of ICAR-CRIDA, and who were the members of the editorial committee for the 2022 annual report?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 55\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mquery_and_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, answer)\n",
      "Cell \u001b[1;32mIn[80], line 48\u001b[0m, in \u001b[0;36mquery_and_answer\u001b[1;34m(query_text)\u001b[0m\n\u001b[0;32m     45\u001b[0m nearest_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Adjust as per your requirement\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Get context based on nearest_ids\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnearest_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Generate answer\u001b[39;00m\n\u001b[0;32m     51\u001b[0m answer \u001b[38;5;241m=\u001b[39m generate_answer(query_text, context)\n",
      "Cell \u001b[1;32mIn[80], line 39\u001b[0m, in \u001b[0;36mget_context\u001b[1;34m(nearest_ids)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_chunks.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     37\u001b[0m     loaded_chunks \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m---> 39\u001b[0m chunks \u001b[38;5;241m=\u001b[39m [\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loaded_chunks) \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m nearest_ids]\n\u001b[0;32m     40\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model for question answering\n",
    "qa_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "qa_tokenizer = BertTokenizer.from_pretrained(qa_model_name)\n",
    "qa_model = BertForQuestionAnswering.from_pretrained(qa_model_name)\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    # Tokenize text chunk and query\n",
    "    query_tokens = qa_tokenizer.encode(query, add_special_tokens=False)\n",
    "    text_chunk_tokens = qa_tokenizer.encode(context, add_special_tokens=False, truncation=True, max_length=500-len(query_tokens))\n",
    "    \n",
    "    # Combine text and query tokens with special tokens\n",
    "    input_tokens = [qa_tokenizer.cls_token_id] + query_tokens + [qa_tokenizer.sep_token_id] + text_chunk_tokens + [qa_tokenizer.sep_token_id]\n",
    "    \n",
    "    # Convert tokens to tensors\n",
    "    input_ids = torch.tensor(input_tokens).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = qa_model(input_ids)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    # Find the answer span with the highest probability\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits)\n",
    "\n",
    "    # Get the answer tokens and convert them to string\n",
    "    answer_tokens = input_tokens[start_index:end_index+1]\n",
    "    answer = qa_tokenizer.decode(answer_tokens)\n",
    "    return answer\n",
    "\n",
    "def get_context(nearest_ids):\n",
    "    with open('text_chunks.pkl', 'rb') as f:\n",
    "        loaded_chunks = pickle.load(f)\n",
    "    \n",
    "    chunks = [chunk['original_text'] for idx, chunk in enumerate(loaded_chunks) if idx in nearest_ids]\n",
    "    context = \" \".join(chunks)\n",
    "    return context\n",
    "\n",
    "def query_and_answer(query_text):\n",
    "    # Perform query and answer generation\n",
    "    nearest_ids = [0, 1]  # Adjust as per your requirement\n",
    "    \n",
    "    # Get context based on nearest_ids\n",
    "    context = get_context(nearest_ids)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = generate_answer(query_text, context)\n",
    "    return answer\n",
    "\n",
    "query_text = \"Who is the current director of ICAR-CRIDA, and who were the members of the editorial committee for the 2022 annual report?\"\n",
    "answer = query_and_answer(query_text)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generate Answer***\n",
    "\n",
    "**Task** : Produce a final answer to the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def generate_answer(query: str, context: str, model_name: str = 'gpt2', max_length: int = 1024) -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer based on the query and context using a GPT-2 model.\n",
    "    \n",
    "    :param query: The query to be answered.\n",
    "    :param context: The context in which to find the answer.\n",
    "    :param model_name: The name of the GPT-2 model to use (default is 'gpt2').\n",
    "    :param max_length: The maximum length of the generated answer.\n",
    "    :return: The generated answer as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare the input text\n",
    "    input_text = f\"Context: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    # Encode the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "    # Generate the output\n",
    "    output_ids = model.generate(input_ids, \n",
    "                                max_length=max_length, \n",
    "                                num_return_sequences=1,\n",
    "                                no_repeat_ngram_size=2, \n",
    "                                temperature=0.5,\n",
    "                                top_p=0.9,\n",
    "                                do_sample=True,\n",
    "                                pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode the output\n",
    "    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Post-process the output to extract the answer part\n",
    "    # answer = answer.split(\"Answer:\")[1].strip()\n",
    "    answer = answer.split(\"Answer:\")[1].strip().split(\"\\n\")[0]\n",
    "\n",
    "    # Tokenize the answer into sentences\n",
    "    sentences = sent_tokenize(answer)\n",
    "\n",
    "    # Reconstruct the answer without the last incomplete sentence\n",
    "    complete_answer = ' '.join(sentences[:-1]) if not answer.endswith('.') else answer\n",
    "\n",
    "    print(\"complete answer: \", complete_answer)\n",
    "    return answer\n",
    "\n",
    "\n",
    "def get_context(nearest_ids):\n",
    "    with open('text_chunks.pkl', 'rb') as f:\n",
    "        loaded_chunks = pickle.load(f)\n",
    "\n",
    "    # nearest_ids.sort()\n",
    "    chunks = [loaded_chunks[i] for i in nearest_ids]\n",
    "    context = \" \".join([i for i in chunks])\n",
    "    print(\"context: \", context)\n",
    "    return context\n",
    "\n",
    "context = get_context(nearest_ids)\n",
    "answer = generate_answer(query, context)\n",
    "print(\"answer: \", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
